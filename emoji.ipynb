{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7da239b8-9a78-4783-bc4a-45c492ed79e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinharshitha/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee176c5-76e0-4d95-829c-9536b07c8635",
   "metadata": {},
   "source": [
    "# Load data from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbf98ce4-67bb-4ffd-bcbd-5ab935171498",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'Emoji_Sentiment_Data_200.csv'\n",
    "data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7f0f84-ff37-4f29-a383-e776e7725205",
   "metadata": {},
   "source": [
    "# Map emojis to indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6374cb8a-3dc9-4d80-9934-89e8d99ea5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "data['Emoji_index'] = label_encoder.fit_transform(data['Emoji'])\n",
    "data['Sentiment'] = label_encoder.fit_transform(data['Sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe13537-24e0-4da9-818c-d65b4f4476d5",
   "metadata": {},
   "source": [
    "# Split data into features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "325eb53b-67ed-48ba-a125-dc77f5166012",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['Emoji_index'].values\n",
    "y = data['Sentiment'].values\n",
    "y = to_categorical(y)  # Convert labels to one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ea666e-aa0c-4100-8a3b-4a6cc04fb2d4",
   "metadata": {},
   "source": [
    "# Split data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a52f12a-6577-4b88-a03e-2e5b19c8ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa52b322-493c-4485-945c-17bb6248ef7d",
   "metadata": {},
   "source": [
    "# Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d46dd30e-b221-49f7-adcf-c7dffdc33eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_emojis = data['Emoji_index'].nunique()\n",
    "embedding_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c2ffbd-98ef-4774-ba5e-14248a19c7cb",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c874080-21bc-49d2-aa3f-21940819a067",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinharshitha/Library/Python/3.9/lib/python/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "2024-08-27 16:02:03.804885: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2024-08-27 16:02:03.804910: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-08-27 16:02:03.804917: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-08-27 16:02:03.805398: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-08-27 16:02:03.805422: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(max_emojis, embedding_size, input_length=1),\n",
    "    LSTM(50),\n",
    "    Dropout(0.5),\n",
    "    Dense(y.shape[1], activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7a9251-5312-4f13-87c5-5267f21c892c",
   "metadata": {},
   "source": [
    "# Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "022958f1-867a-423a-9c4d-1ae7bb654de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58572e8f-6c82-474c-b985-66189371462c",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6aa499f4-8a79-44dc-8b78-c5ac083ffb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"lstm\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 50)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/layers/input_spec.py:186\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mallow_last_axis_squeeze:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;241m!=\u001b[39m spec\u001b[38;5;241m.\u001b[39mndim:\n\u001b[0;32m--> 186\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    187\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    188\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis incompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    189\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, found ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull shape received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mmax_ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m ndim \u001b[38;5;241m>\u001b[39m spec\u001b[38;5;241m.\u001b[39mmax_ndim:\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"lstm\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 50)"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09893c3c-6f5c-4750-8ab5-2a9465c67be1",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fcbe4e-2e59-4bba-87ab-a1b400e02012",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('emoji_sentiment_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5def417-9498-4284-97dd-754d7a43a11c",
   "metadata": {},
   "source": [
    "# Load and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b27354-f150-4d1d-b4d0-c95b694b0330",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model('emoji_sentiment_model.h5')\n",
    "loss, accuracy = loaded_model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219ed599-d6fd-44bd-b851-86582d9968e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce7bba86-8a98-456c-b6a7-7bc108c85f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinharshitha/Library/Python/3.9/lib/python/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.2796 - loss: 1.0990 - val_accuracy: 0.5000 - val_loss: 1.0978\n",
      "Epoch 2/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4089 - loss: 1.0968 - val_accuracy: 0.4211 - val_loss: 1.0973\n",
      "Epoch 3/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4238 - loss: 1.0961 - val_accuracy: 0.4211 - val_loss: 1.0968\n",
      "Epoch 4/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6024 - loss: 1.0917 - val_accuracy: 0.4211 - val_loss: 1.0963\n",
      "Epoch 5/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6904 - loss: 1.0875 - val_accuracy: 0.4211 - val_loss: 1.0956\n",
      "Epoch 6/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6171 - loss: 1.0856 - val_accuracy: 0.4211 - val_loss: 1.0950\n",
      "Epoch 7/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6563 - loss: 1.0808 - val_accuracy: 0.4474 - val_loss: 1.0944\n",
      "Epoch 8/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7560 - loss: 1.0762 - val_accuracy: 0.4211 - val_loss: 1.0938\n",
      "Epoch 9/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7657 - loss: 1.0689 - val_accuracy: 0.3947 - val_loss: 1.0932\n",
      "Epoch 10/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8114 - loss: 1.0599 - val_accuracy: 0.3947 - val_loss: 1.0925\n",
      "Epoch 11/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8847 - loss: 1.0484 - val_accuracy: 0.4211 - val_loss: 1.0918\n",
      "Epoch 12/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9570 - loss: 1.0340 - val_accuracy: 0.4211 - val_loss: 1.0909\n",
      "Epoch 13/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9667 - loss: 1.0148 - val_accuracy: 0.4211 - val_loss: 1.0904\n",
      "Epoch 14/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9703 - loss: 0.9898 - val_accuracy: 0.4211 - val_loss: 1.0897\n",
      "Epoch 15/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9668 - loss: 0.9622 - val_accuracy: 0.4211 - val_loss: 1.0890\n",
      "Epoch 16/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9829 - loss: 0.9279 - val_accuracy: 0.4211 - val_loss: 1.0887\n",
      "Epoch 17/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9733 - loss: 0.8847 - val_accuracy: 0.3947 - val_loss: 1.0885\n",
      "Epoch 18/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9598 - loss: 0.8530 - val_accuracy: 0.3684 - val_loss: 1.0888\n",
      "Epoch 19/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9572 - loss: 0.8024 - val_accuracy: 0.3684 - val_loss: 1.0892\n",
      "Epoch 20/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9759 - loss: 0.7253 - val_accuracy: 0.3684 - val_loss: 1.0903\n",
      "Epoch 21/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9794 - loss: 0.6734 - val_accuracy: 0.3684 - val_loss: 1.0917\n",
      "Epoch 22/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9729 - loss: 0.6091 - val_accuracy: 0.3947 - val_loss: 1.0943\n",
      "Epoch 23/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9685 - loss: 0.5414 - val_accuracy: 0.3947 - val_loss: 1.0975\n",
      "Epoch 24/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9660 - loss: 0.4629 - val_accuracy: 0.3684 - val_loss: 1.1024\n",
      "Epoch 25/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9677 - loss: 0.4111 - val_accuracy: 0.3684 - val_loss: 1.1085\n",
      "Epoch 26/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9694 - loss: 0.3360 - val_accuracy: 0.3684 - val_loss: 1.1156\n",
      "Epoch 27/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9655 - loss: 0.2947 - val_accuracy: 0.3947 - val_loss: 1.1233\n",
      "Epoch 28/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9759 - loss: 0.2549 - val_accuracy: 0.3947 - val_loss: 1.1323\n",
      "Epoch 29/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9716 - loss: 0.2188 - val_accuracy: 0.3684 - val_loss: 1.1417\n",
      "Epoch 30/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9659 - loss: 0.1859 - val_accuracy: 0.3684 - val_loss: 1.1517\n",
      "Epoch 31/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9716 - loss: 0.1680 - val_accuracy: 0.3684 - val_loss: 1.1622\n",
      "Epoch 32/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9555 - loss: 0.1561 - val_accuracy: 0.3684 - val_loss: 1.1722\n",
      "Epoch 33/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9733 - loss: 0.1290 - val_accuracy: 0.3684 - val_loss: 1.1811\n",
      "Epoch 34/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9533 - loss: 0.1254 - val_accuracy: 0.3684 - val_loss: 1.1895\n",
      "Epoch 35/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9834 - loss: 0.1137 - val_accuracy: 0.3684 - val_loss: 1.1972\n",
      "Epoch 36/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9832 - loss: 0.0899 - val_accuracy: 0.3684 - val_loss: 1.2046\n",
      "Epoch 37/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9759 - loss: 0.0852 - val_accuracy: 0.3684 - val_loss: 1.2114\n",
      "Epoch 38/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9825 - loss: 0.0696 - val_accuracy: 0.3947 - val_loss: 1.2176\n",
      "Epoch 39/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9739 - loss: 0.0838 - val_accuracy: 0.4211 - val_loss: 1.2235\n",
      "Epoch 40/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9658 - loss: 0.0692 - val_accuracy: 0.3947 - val_loss: 1.2287\n",
      "Epoch 41/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9681 - loss: 0.0795 - val_accuracy: 0.3947 - val_loss: 1.2338\n",
      "Epoch 42/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9716 - loss: 0.0718 - val_accuracy: 0.3947 - val_loss: 1.2385\n",
      "Epoch 43/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9703 - loss: 0.0621 - val_accuracy: 0.3947 - val_loss: 1.2432\n",
      "Epoch 44/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9624 - loss: 0.0732 - val_accuracy: 0.3947 - val_loss: 1.2474\n",
      "Epoch 45/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9611 - loss: 0.0627 - val_accuracy: 0.3947 - val_loss: 1.2513\n",
      "Epoch 46/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9759 - loss: 0.0522 - val_accuracy: 0.3947 - val_loss: 1.2548\n",
      "Epoch 47/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9625 - loss: 0.0782 - val_accuracy: 0.3947 - val_loss: 1.2582\n",
      "Epoch 48/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9947 - loss: 0.0546 - val_accuracy: 0.3947 - val_loss: 1.2614\n",
      "Epoch 49/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9651 - loss: 0.0645 - val_accuracy: 0.3947 - val_loss: 1.2647\n",
      "Epoch 50/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9550 - loss: 0.0732 - val_accuracy: 0.3947 - val_loss: 1.2679\n",
      "Epoch 51/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9702 - loss: 0.0508 - val_accuracy: 0.3947 - val_loss: 1.2711\n",
      "Epoch 52/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9660 - loss: 0.0607 - val_accuracy: 0.3947 - val_loss: 1.2742\n",
      "Epoch 53/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9712 - loss: 0.0709 - val_accuracy: 0.3947 - val_loss: 1.2774\n",
      "Epoch 54/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9759 - loss: 0.0468 - val_accuracy: 0.3947 - val_loss: 1.2802\n",
      "Epoch 55/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9877 - loss: 0.0345 - val_accuracy: 0.3947 - val_loss: 1.2830\n",
      "Epoch 56/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9899 - loss: 0.0412 - val_accuracy: 0.3947 - val_loss: 1.2857\n",
      "Epoch 57/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9886 - loss: 0.0438 - val_accuracy: 0.3947 - val_loss: 1.2884\n",
      "Epoch 58/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9824 - loss: 0.0374 - val_accuracy: 0.3947 - val_loss: 1.2912\n",
      "Epoch 59/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9899 - loss: 0.0403 - val_accuracy: 0.3947 - val_loss: 1.2944\n",
      "Epoch 60/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9624 - loss: 0.0499 - val_accuracy: 0.3947 - val_loss: 1.2971\n",
      "Epoch 61/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9653 - loss: 0.0414 - val_accuracy: 0.3947 - val_loss: 1.2996\n",
      "Epoch 62/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9685 - loss: 0.0585 - val_accuracy: 0.3947 - val_loss: 1.3019\n",
      "Epoch 63/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9873 - loss: 0.0394 - val_accuracy: 0.3947 - val_loss: 1.3043\n",
      "Epoch 64/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9903 - loss: 0.0396 - val_accuracy: 0.4211 - val_loss: 1.3067\n",
      "Epoch 65/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9895 - loss: 0.0356 - val_accuracy: 0.4211 - val_loss: 1.3087\n",
      "Epoch 66/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9794 - loss: 0.0488 - val_accuracy: 0.4211 - val_loss: 1.3106\n",
      "Epoch 67/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9943 - loss: 0.0382 - val_accuracy: 0.4211 - val_loss: 1.3123\n",
      "Epoch 68/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9741 - loss: 0.0388 - val_accuracy: 0.4211 - val_loss: 1.3139\n",
      "Epoch 69/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9799 - loss: 0.0485 - val_accuracy: 0.4211 - val_loss: 1.3158\n",
      "Epoch 70/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9781 - loss: 0.0386 - val_accuracy: 0.3947 - val_loss: 1.3179\n",
      "Epoch 71/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9811 - loss: 0.0357 - val_accuracy: 0.3947 - val_loss: 1.3198\n",
      "Epoch 72/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9825 - loss: 0.0414 - val_accuracy: 0.3947 - val_loss: 1.3215\n",
      "Epoch 73/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9733 - loss: 0.0476 - val_accuracy: 0.3947 - val_loss: 1.3233\n",
      "Epoch 74/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9763 - loss: 0.0471 - val_accuracy: 0.3947 - val_loss: 1.3247\n",
      "Epoch 75/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9834 - loss: 0.0425 - val_accuracy: 0.3947 - val_loss: 1.3261\n",
      "Epoch 76/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9572 - loss: 0.0648 - val_accuracy: 0.3947 - val_loss: 1.3277\n",
      "Epoch 77/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9947 - loss: 0.0361 - val_accuracy: 0.3947 - val_loss: 1.3302\n",
      "Epoch 78/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9581 - loss: 0.0518 - val_accuracy: 0.3947 - val_loss: 1.3321\n",
      "Epoch 79/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9607 - loss: 0.0624 - val_accuracy: 0.3947 - val_loss: 1.3336\n",
      "Epoch 80/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9777 - loss: 0.0458 - val_accuracy: 0.3947 - val_loss: 1.3348\n",
      "Epoch 81/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9785 - loss: 0.0445 - val_accuracy: 0.4211 - val_loss: 1.3360\n",
      "Epoch 82/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9477 - loss: 0.0670 - val_accuracy: 0.4211 - val_loss: 1.3372\n",
      "Epoch 83/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9799 - loss: 0.0510 - val_accuracy: 0.4211 - val_loss: 1.3385\n",
      "Epoch 84/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9624 - loss: 0.0483 - val_accuracy: 0.4211 - val_loss: 1.3398\n",
      "Epoch 85/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9956 - loss: 0.0295 - val_accuracy: 0.4211 - val_loss: 1.3411\n",
      "Epoch 86/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9772 - loss: 0.0411 - val_accuracy: 0.4211 - val_loss: 1.3423\n",
      "Epoch 87/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9554 - loss: 0.0572 - val_accuracy: 0.4211 - val_loss: 1.3432\n",
      "Epoch 88/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9794 - loss: 0.0448 - val_accuracy: 0.4211 - val_loss: 1.3442\n",
      "Epoch 89/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9825 - loss: 0.0513 - val_accuracy: 0.4211 - val_loss: 1.3454\n",
      "Epoch 90/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9877 - loss: 0.0312 - val_accuracy: 0.4211 - val_loss: 1.3467\n",
      "Epoch 91/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9559 - loss: 0.0484 - val_accuracy: 0.4211 - val_loss: 1.3481\n",
      "Epoch 92/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9886 - loss: 0.0416 - val_accuracy: 0.4211 - val_loss: 1.3495\n",
      "Epoch 93/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9733 - loss: 0.0440 - val_accuracy: 0.4211 - val_loss: 1.3510\n",
      "Epoch 94/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9869 - loss: 0.0347 - val_accuracy: 0.4211 - val_loss: 1.3524\n",
      "Epoch 95/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9791 - loss: 0.0511 - val_accuracy: 0.4211 - val_loss: 1.3536\n",
      "Epoch 96/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9706 - loss: 0.0429 - val_accuracy: 0.4211 - val_loss: 1.3548\n",
      "Epoch 97/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9529 - loss: 0.0667 - val_accuracy: 0.4211 - val_loss: 1.3557\n",
      "Epoch 98/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9907 - loss: 0.0273 - val_accuracy: 0.4211 - val_loss: 1.3567\n",
      "Epoch 99/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9711 - loss: 0.0463 - val_accuracy: 0.4211 - val_loss: 1.3578\n",
      "Epoch 100/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9842 - loss: 0.0289 - val_accuracy: 0.4211 - val_loss: 1.3588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the dataset\n",
    "data_path = 'Emoji_Sentiment_Data_200.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Encode emojis to indices\n",
    "emoji_encoder = LabelEncoder()\n",
    "data['Emoji_index'] = emoji_encoder.fit_transform(data['Emoji'])\n",
    "\n",
    "# Encode sentiments to categorical labels\n",
    "sentiment_encoder = LabelEncoder()\n",
    "data['Sentiment_label'] = sentiment_encoder.fit_transform(data['Sentiment'])\n",
    "y = to_categorical(data['Sentiment_label'])  # Convert labels to one-hot encoding\n",
    "\n",
    "# Split data into features and target\n",
    "X = data['Emoji_index'].values\n",
    "X = X.reshape(-1, 1)  # Reshape for LSTM input\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define maximum number of unique emojis and embedding size\n",
    "max_emojis = data['Emoji_index'].nunique()\n",
    "embedding_size = 50\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=max_emojis, output_dim=embedding_size, input_length=1),\n",
    "    LSTM(50),\n",
    "    Dropout(0.5),\n",
    "    Dense(y.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, validation_split=0.2)\n",
    "\n",
    "# Save the model\n",
    "model.save('emoji_sentiment_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac9862bf-4965-418a-b840-8a3d27d40bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Object arrays cannot be loaded when allow_pickle=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Load the encoders\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Assuming `emoji_encoder` and `sentiment_encoder` are saved and loaded correctly\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# For simplicity, redefining them here. Make sure to use the actual objects used during training.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m emoji_encoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[0;32m---> 19\u001b[0m emoji_encoder\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43memoji_classes.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Load previously saved emoji classes\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Test data\u001b[39;00m\n\u001b[1;32m     22\u001b[0m test_sentences \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI love this new song ğŸ˜!\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI am not sure about this ğŸ˜\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is absolutely terrible ğŸ˜\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParty time! ğŸ‰\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m ]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/numpy/lib/npyio.py:456\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mopen_memmap(file, mode\u001b[38;5;241m=\u001b[39mmmap_mode,\n\u001b[1;32m    454\u001b[0m                                   max_header_size\u001b[38;5;241m=\u001b[39mmax_header_size)\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 456\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/numpy/lib/format.py:795\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mhasobject:\n\u001b[1;32m    793\u001b[0m     \u001b[38;5;66;03m# The array contained Python objects. We need to unpickle the data.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n\u001b[0;32m--> 795\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObject arrays cannot be loaded when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    796\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_pickle=False\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    797\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pickle_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    798\u001b[0m         pickle_kwargs \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[0;31mValueError\u001b[0m: Object arrays cannot be loaded when allow_pickle=False"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Function to extract emojis from a text\n",
    "def extract_emojis(text):\n",
    "    return [char for char in text if char in emoji_encoder.classes_]\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('emoji_sentiment_model.h5')\n",
    "\n",
    "# Load the encoders\n",
    "# Assuming `emoji_encoder` and `sentiment_encoder` are saved and loaded correctly\n",
    "# For simplicity, redefining them here. Make sure to use the actual objects used during training.\n",
    "emoji_encoder = LabelEncoder()\n",
    "emoji_encoder.classes_ = np.load('emoji_classes.npy')  # Load previously saved emoji classes\n",
    "\n",
    "# Test data\n",
    "test_sentences = [\n",
    "    \"I love this new song ğŸ˜!\",\n",
    "    \"I am not sure about this ğŸ˜\",\n",
    "    \"This is absolutely terrible ğŸ˜\",\n",
    "    \"Party time! ğŸ‰\"\n",
    "]\n",
    "\n",
    "# Process each sentence\n",
    "for sentence in test_sentences:\n",
    "    emojis = extract_emojis(sentence)\n",
    "    if emojis:\n",
    "        # Convert emojis to indices\n",
    "        emoji_indices = emoji_encoder.transform(emojis)\n",
    "        emoji_indices = np.array(emoji_indices).reshape(-1, 1)\n",
    "\n",
    "        # Predict sentiment\n",
    "        predictions = model.predict(emoji_indices)\n",
    "        predicted_sentiments = np.argmax(predictions, axis=1)\n",
    "        predicted_sentiments = [sentiment_encoder.inverse_transform([pred])[0] for pred in predicted_sentiments]\n",
    "\n",
    "        print(f\"Sentence: '{sentence}'\")\n",
    "        for emoji, sentiment in zip(emojis, predicted_sentiments):\n",
    "            print(f\"  Emoji: '{emoji}' - Sentiment: '{sentiment}'\")\n",
    "    else:\n",
    "        print(f\"Sentence: '{sentence}' - No emojis found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de56578c-b911-4a46-8f18-834cf69ad2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinharshitha/Library/Python/3.9/lib/python/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.3331 - loss: 1.0981 - val_accuracy: 0.5000 - val_loss: 1.0975\n",
      "Epoch 2/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4177 - loss: 1.0966 - val_accuracy: 0.4737 - val_loss: 1.0969\n",
      "Epoch 3/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4649 - loss: 1.0950 - val_accuracy: 0.4737 - val_loss: 1.0966\n",
      "Epoch 4/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4758 - loss: 1.0939 - val_accuracy: 0.4737 - val_loss: 1.0962\n",
      "Epoch 5/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4898 - loss: 1.0919 - val_accuracy: 0.4474 - val_loss: 1.0960\n",
      "Epoch 6/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5132 - loss: 1.0885 - val_accuracy: 0.4474 - val_loss: 1.0958\n",
      "Epoch 7/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5847 - loss: 1.0861 - val_accuracy: 0.4474 - val_loss: 1.0955\n",
      "Epoch 8/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6307 - loss: 1.0792 - val_accuracy: 0.4211 - val_loss: 1.0952\n",
      "Epoch 9/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6961 - loss: 1.0756 - val_accuracy: 0.4474 - val_loss: 1.0950\n",
      "Epoch 10/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7451 - loss: 1.0684 - val_accuracy: 0.4474 - val_loss: 1.0947\n",
      "Epoch 11/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8086 - loss: 1.0590 - val_accuracy: 0.4474 - val_loss: 1.0946\n",
      "Epoch 12/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9090 - loss: 1.0456 - val_accuracy: 0.4737 - val_loss: 1.0944\n",
      "Epoch 13/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9479 - loss: 1.0292 - val_accuracy: 0.4737 - val_loss: 1.0944\n",
      "Epoch 14/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9558 - loss: 1.0103 - val_accuracy: 0.4474 - val_loss: 1.0944\n",
      "Epoch 15/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9710 - loss: 0.9885 - val_accuracy: 0.4737 - val_loss: 1.0945\n",
      "Epoch 16/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9659 - loss: 0.9584 - val_accuracy: 0.4737 - val_loss: 1.0949\n",
      "Epoch 17/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9607 - loss: 0.9310 - val_accuracy: 0.4737 - val_loss: 1.0957\n",
      "Epoch 18/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9716 - loss: 0.8855 - val_accuracy: 0.4737 - val_loss: 1.0968\n",
      "Epoch 19/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9755 - loss: 0.8360 - val_accuracy: 0.5000 - val_loss: 1.0983\n",
      "Epoch 20/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9791 - loss: 0.7879 - val_accuracy: 0.4737 - val_loss: 1.1005\n",
      "Epoch 21/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9625 - loss: 0.7317 - val_accuracy: 0.4474 - val_loss: 1.1033\n",
      "Epoch 22/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9716 - loss: 0.6529 - val_accuracy: 0.4474 - val_loss: 1.1071\n",
      "Epoch 23/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9855 - loss: 0.5804 - val_accuracy: 0.4474 - val_loss: 1.1123\n",
      "Epoch 24/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9746 - loss: 0.5189 - val_accuracy: 0.4474 - val_loss: 1.1183\n",
      "Epoch 25/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9581 - loss: 0.4685 - val_accuracy: 0.4211 - val_loss: 1.1254\n",
      "Epoch 26/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9694 - loss: 0.4003 - val_accuracy: 0.4211 - val_loss: 1.1336\n",
      "Epoch 27/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9794 - loss: 0.3195 - val_accuracy: 0.4211 - val_loss: 1.1429\n",
      "Epoch 28/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9811 - loss: 0.2845 - val_accuracy: 0.4211 - val_loss: 1.1521\n",
      "Epoch 29/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9602 - loss: 0.2412 - val_accuracy: 0.4211 - val_loss: 1.1619\n",
      "Epoch 30/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9869 - loss: 0.2066 - val_accuracy: 0.4474 - val_loss: 1.1722\n",
      "Epoch 31/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9555 - loss: 0.1939 - val_accuracy: 0.4474 - val_loss: 1.1817\n",
      "Epoch 32/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9667 - loss: 0.1492 - val_accuracy: 0.4474 - val_loss: 1.1909\n",
      "Epoch 33/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9619 - loss: 0.1252 - val_accuracy: 0.4474 - val_loss: 1.1996\n",
      "Epoch 34/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9781 - loss: 0.1221 - val_accuracy: 0.4474 - val_loss: 1.2077\n",
      "Epoch 35/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9720 - loss: 0.1057 - val_accuracy: 0.4474 - val_loss: 1.2151\n",
      "Epoch 36/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9834 - loss: 0.1061 - val_accuracy: 0.4474 - val_loss: 1.2221\n",
      "Epoch 37/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9625 - loss: 0.1099 - val_accuracy: 0.4474 - val_loss: 1.2288\n",
      "Epoch 38/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9847 - loss: 0.0771 - val_accuracy: 0.4211 - val_loss: 1.2347\n",
      "Epoch 39/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9628 - loss: 0.0881 - val_accuracy: 0.4211 - val_loss: 1.2407\n",
      "Epoch 40/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9680 - loss: 0.0701 - val_accuracy: 0.3947 - val_loss: 1.2462\n",
      "Epoch 41/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9668 - loss: 0.0866 - val_accuracy: 0.3947 - val_loss: 1.2514\n",
      "Epoch 42/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9581 - loss: 0.0864 - val_accuracy: 0.3947 - val_loss: 1.2564\n",
      "Epoch 43/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9802 - loss: 0.0635 - val_accuracy: 0.3947 - val_loss: 1.2613\n",
      "Epoch 44/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9824 - loss: 0.0671 - val_accuracy: 0.3947 - val_loss: 1.2656\n",
      "Epoch 45/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9519 - loss: 0.0710 - val_accuracy: 0.3947 - val_loss: 1.2696\n",
      "Epoch 46/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9759 - loss: 0.0589 - val_accuracy: 0.3947 - val_loss: 1.2733\n",
      "Epoch 47/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9715 - loss: 0.0581 - val_accuracy: 0.3947 - val_loss: 1.2766\n",
      "Epoch 48/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9798 - loss: 0.0537 - val_accuracy: 0.3947 - val_loss: 1.2803\n",
      "Epoch 49/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9519 - loss: 0.0645 - val_accuracy: 0.3947 - val_loss: 1.2839\n",
      "Epoch 50/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9903 - loss: 0.0459 - val_accuracy: 0.3947 - val_loss: 1.2872\n",
      "Epoch 51/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9978 - loss: 0.0546 - val_accuracy: 0.3947 - val_loss: 1.2913\n",
      "Epoch 52/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9790 - loss: 0.0568 - val_accuracy: 0.3947 - val_loss: 1.2952\n",
      "Epoch 53/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9817 - loss: 0.0626 - val_accuracy: 0.3947 - val_loss: 1.2987\n",
      "Epoch 54/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9681 - loss: 0.0564 - val_accuracy: 0.4211 - val_loss: 1.3025\n",
      "Epoch 55/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9654 - loss: 0.0536 - val_accuracy: 0.3947 - val_loss: 1.3060\n",
      "Epoch 56/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9638 - loss: 0.0603 - val_accuracy: 0.3947 - val_loss: 1.3089\n",
      "Epoch 57/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9956 - loss: 0.0433 - val_accuracy: 0.3947 - val_loss: 1.3117\n",
      "Epoch 58/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9615 - loss: 0.0557 - val_accuracy: 0.3947 - val_loss: 1.3144\n",
      "Epoch 59/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9703 - loss: 0.0539 - val_accuracy: 0.3947 - val_loss: 1.3167\n",
      "Epoch 60/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9476 - loss: 0.0681 - val_accuracy: 0.3947 - val_loss: 1.3192\n",
      "Epoch 61/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9811 - loss: 0.0496 - val_accuracy: 0.3947 - val_loss: 1.3212\n",
      "Epoch 62/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9873 - loss: 0.0395 - val_accuracy: 0.3947 - val_loss: 1.3234\n",
      "Epoch 63/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9724 - loss: 0.0504 - val_accuracy: 0.3947 - val_loss: 1.3256\n",
      "Epoch 64/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9607 - loss: 0.0547 - val_accuracy: 0.3947 - val_loss: 1.3277\n",
      "Epoch 65/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9847 - loss: 0.0406 - val_accuracy: 0.3947 - val_loss: 1.3301\n",
      "Epoch 66/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9650 - loss: 0.0542 - val_accuracy: 0.3947 - val_loss: 1.3323\n",
      "Epoch 67/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9742 - loss: 0.0456 - val_accuracy: 0.3947 - val_loss: 1.3343\n",
      "Epoch 68/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9781 - loss: 0.0447 - val_accuracy: 0.3947 - val_loss: 1.3360\n",
      "Epoch 69/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9524 - loss: 0.0553 - val_accuracy: 0.3947 - val_loss: 1.3378\n",
      "Epoch 70/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9690 - loss: 0.0572 - val_accuracy: 0.3947 - val_loss: 1.3393\n",
      "Epoch 71/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9737 - loss: 0.0459 - val_accuracy: 0.3947 - val_loss: 1.3408\n",
      "Epoch 72/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9817 - loss: 0.0444 - val_accuracy: 0.3947 - val_loss: 1.3424\n",
      "Epoch 73/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9824 - loss: 0.0278 - val_accuracy: 0.3947 - val_loss: 1.3441\n",
      "Epoch 74/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9920 - loss: 0.0337 - val_accuracy: 0.3947 - val_loss: 1.3458\n",
      "Epoch 75/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9598 - loss: 0.0548 - val_accuracy: 0.3947 - val_loss: 1.3473\n",
      "Epoch 76/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9837 - loss: 0.0413 - val_accuracy: 0.3947 - val_loss: 1.3489\n",
      "Epoch 77/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9781 - loss: 0.0394 - val_accuracy: 0.3947 - val_loss: 1.3507\n",
      "Epoch 78/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9363 - loss: 0.0746 - val_accuracy: 0.3947 - val_loss: 1.3520\n",
      "Epoch 79/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9907 - loss: 0.0334 - val_accuracy: 0.3947 - val_loss: 1.3533\n",
      "Epoch 80/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9615 - loss: 0.0575 - val_accuracy: 0.3947 - val_loss: 1.3544\n",
      "Epoch 81/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9807 - loss: 0.0416 - val_accuracy: 0.3947 - val_loss: 1.3560\n",
      "Epoch 82/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9624 - loss: 0.0488 - val_accuracy: 0.3947 - val_loss: 1.3576\n",
      "Epoch 83/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9750 - loss: 0.0414 - val_accuracy: 0.3947 - val_loss: 1.3590\n",
      "Epoch 84/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9668 - loss: 0.0440 - val_accuracy: 0.4211 - val_loss: 1.3602\n",
      "Epoch 85/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9602 - loss: 0.0439 - val_accuracy: 0.4211 - val_loss: 1.3614\n",
      "Epoch 86/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9733 - loss: 0.0465 - val_accuracy: 0.4211 - val_loss: 1.3627\n",
      "Epoch 87/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9572 - loss: 0.0650 - val_accuracy: 0.3947 - val_loss: 1.3639\n",
      "Epoch 88/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9895 - loss: 0.0378 - val_accuracy: 0.3947 - val_loss: 1.3649\n",
      "Epoch 89/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9825 - loss: 0.0341 - val_accuracy: 0.3947 - val_loss: 1.3662\n",
      "Epoch 90/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9869 - loss: 0.0383 - val_accuracy: 0.3947 - val_loss: 1.3676\n",
      "Epoch 91/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9476 - loss: 0.0504 - val_accuracy: 0.3947 - val_loss: 1.3689\n",
      "Epoch 92/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9837 - loss: 0.0286 - val_accuracy: 0.3947 - val_loss: 1.3703\n",
      "Epoch 93/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9633 - loss: 0.0556 - val_accuracy: 0.3947 - val_loss: 1.3713\n",
      "Epoch 94/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9825 - loss: 0.0482 - val_accuracy: 0.3947 - val_loss: 1.3726\n",
      "Epoch 95/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9834 - loss: 0.0439 - val_accuracy: 0.3947 - val_loss: 1.3736\n",
      "Epoch 96/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9739 - loss: 0.0395 - val_accuracy: 0.4211 - val_loss: 1.3750\n",
      "Epoch 97/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9816 - loss: 0.0328 - val_accuracy: 0.4211 - val_loss: 1.3763\n",
      "Epoch 98/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9733 - loss: 0.0385 - val_accuracy: 0.4211 - val_loss: 1.3777\n",
      "Epoch 99/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9694 - loss: 0.0425 - val_accuracy: 0.4211 - val_loss: 1.3790\n",
      "Epoch 100/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9659 - loss: 0.0617 - val_accuracy: 0.4211 - val_loss: 1.3800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.3993 - loss: 1.6193 \n",
      "Test Accuracy: 0.40\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the dataset\n",
    "data_path = 'Emoji_Sentiment_Data_200.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Encode emojis to indices\n",
    "emoji_encoder = LabelEncoder()\n",
    "data['Emoji_index'] = emoji_encoder.fit_transform(data['Emoji'])\n",
    "# Save emoji classes for later use\n",
    "np.save('emoji_classes.npy', emoji_encoder.classes_)\n",
    "\n",
    "# Encode sentiments to categorical labels\n",
    "sentiment_encoder = LabelEncoder()\n",
    "data['Sentiment_label'] = sentiment_encoder.fit_transform(data['Sentiment'])\n",
    "y = to_categorical(data['Sentiment_label'])  # Convert labels to one-hot encoding\n",
    "# Save sentiment classes for later use\n",
    "np.save('sentiment_classes.npy', sentiment_encoder.classes_)\n",
    "\n",
    "# Split data into features and target\n",
    "X = data['Emoji_index'].values\n",
    "X = X.reshape(-1, 1)  # Reshape for LSTM input\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define maximum number of unique emojis and embedding size\n",
    "max_emojis = data['Emoji_index'].nunique()\n",
    "embedding_size = 50\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=max_emojis, output_dim=embedding_size, input_length=1),\n",
    "    LSTM(50),\n",
    "    Dropout(0.5),\n",
    "    Dense(y.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, validation_split=0.2)\n",
    "\n",
    "# Save the model\n",
    "model.save('emoji_sentiment_model.h5')\n",
    "\n",
    "# Load the model (optional, demonstration)\n",
    "loaded_model = load_model('emoji_sentiment_model.h5')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = loaded_model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_acc:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de7b1aa7-5178-42e0-8348-cde26253f550",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 972ms/step\n",
      "Sentence: 'I love this new song ğŸ˜!'\n",
      "  Emoji: 'ğŸ˜' - Sentiment: 'neutral'\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "Sentence: 'I am not sure about this ğŸ˜'\n",
      "  Emoji: 'ğŸ˜' - Sentiment: 'neutral'\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Sentence: 'This is absolutely terrible ğŸ˜'\n",
      "  Emoji: 'ğŸ˜' - Sentiment: 'negative'\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Sentence: 'Party time! ğŸ‰'\n",
      "  Emoji: 'ğŸ‰' - Sentiment: 'positive'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Function to extract emojis from text\n",
    "def extract_emojis(text):\n",
    "    return [char for char in text if char in emoji_encoder.classes_]\n",
    "\n",
    "# Load the model\n",
    "model = load_model('emoji_sentiment_model.h5')\n",
    "\n",
    "# Load the encoders\n",
    "emoji_encoder = LabelEncoder()\n",
    "emoji_encoder.classes_ = np.load('emoji_classes.npy', allow_pickle=True)  # Load emoji classes\n",
    "\n",
    "sentiment_encoder = LabelEncoder()\n",
    "sentiment_encoder.classes_ = np.load('sentiment_classes.npy', allow_pickle=True)  # Load sentiment classes\n",
    "\n",
    "# Example sentences with emojis\n",
    "test_sentences = [\n",
    "    \"I love this new song ğŸ˜!\",\n",
    "    \"I am not sure about this ğŸ˜\",\n",
    "    \"This is absolutely terrible ğŸ˜\",\n",
    "    \"Party time! ğŸ‰\"\n",
    "]\n",
    "\n",
    "# Process each sentence\n",
    "for sentence in test_sentences:\n",
    "    emojis = extract_emojis(sentence)\n",
    "    if emojis:\n",
    "        emoji_indices = emoji_encoder.transform(emojis)\n",
    "        emoji_indices = np.array(emoji_indices).reshape(-1, 1)\n",
    "        predictions = model.predict(emoji_indices)\n",
    "        predicted_sentiments = np.argmax(predictions, axis=1)\n",
    "        predicted_sentiments = [sentiment_encoder.inverse_transform([pred])[0] for pred in predicted_sentiments]\n",
    "\n",
    "        print(f\"Sentence: '{sentence}'\")\n",
    "        for emoji, sentiment in zip(emojis, predicted_sentiments):\n",
    "            print(f\"  Emoji: '{emoji}' - Sentiment: '{sentiment}'\")\n",
    "    else:\n",
    "        print(f\"Sentence: '{sentence}' - No emojis found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92d8df9f-1a0e-47fc-a959-c350ef2d52b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ErnieTokenizer' from 'transformers' (C:\\Users\\Micheal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ErnieModel, ErnieTokenizer\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'ErnieTokenizer' from 'transformers' (C:\\Users\\Micheal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import ErnieModel, ErnieTokenizer\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the dataset\n",
    "data_path = 'Emoji_Sentiment_Data_200.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Encode emojis to indices\n",
    "emoji_encoder = LabelEncoder()\n",
    "data['Emoji_index'] = emoji_encoder.fit_transform(data['Emoji'])\n",
    "\n",
    "# Encode sentiments to categorical labels\n",
    "sentiment_encoder = LabelEncoder()\n",
    "data['Sentiment_label'] = sentiment_encoder.fit_transform(data['Sentiment'])\n",
    "y = data['Sentiment_label']\n",
    "\n",
    "# Load ERINE tokenizer and model\n",
    "tokenizer = ErnieTokenizer.from_pretrained('nghuyong/ernie-1.0')\n",
    "ernie_model = ErnieModel.from_pretrained('nghuyong/ernie-1.0')\n",
    "\n",
    "# Freeze ERINE layers (optional)\n",
    "for param in ernie_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Tokenize emoji indices\n",
    "X = data['Emoji_index'].apply(lambda x: tokenizer.encode(str(x), return_tensors='pt')[0])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.tolist(), y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to tensor for PyTorch\n",
    "X_train = torch.stack([torch.tensor(x) for x in X_train])\n",
    "y_train = torch.tensor(y_train.values)\n",
    "X_test = torch.stack([torch.tensor(x) for x in X_test])\n",
    "y_test = torch.tensor(y_test.values)\n",
    "\n",
    "# Define a custom model combining ERINE and LSTM\n",
    "class ErineLSTMModel(nn.Module):\n",
    "    def __init__(self, ernie_model, lstm_hidden_size, num_labels):\n",
    "        super(ErineLSTMModel, self).__init__()\n",
    "        self.ernie = ernie_model\n",
    "        self.lstm = nn.LSTM(input_size=ernie_model.config.hidden_size, hidden_size=lstm_hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(lstm_hidden_size, num_labels)\n",
    "        \n",
    "    def forward(self, input_ids):\n",
    "        # Get ERINE embeddings\n",
    "        with torch.no_grad():  # Disable gradients for ERINE if frozen\n",
    "            outputs = self.ernie(input_ids)\n",
    "            ernie_output = outputs.last_hidden_state\n",
    "        \n",
    "        # Pass embeddings through LSTM\n",
    "        lstm_output, _ = self.lstm(ernie_output)\n",
    "        lstm_output = lstm_output[:, -1, :]  # Take output from the last time step\n",
    "        \n",
    "        # Apply dropout and fully connected layer\n",
    "        lstm_output = self.dropout(lstm_output)\n",
    "        logits = self.fc(lstm_output)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "# Create the model\n",
    "num_labels = len(data['Sentiment'].unique())\n",
    "lstm_hidden_size = 50\n",
    "model = ErineLSTMModel(ernie_model, lstm_hidden_size, num_labels)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(3):  # Train for 3 epochs\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = loss_fn(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch+1} loss: {loss.item()}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test)\n",
    "    predictions = torch.argmax(outputs, dim=-1)\n",
    "    accuracy = accuracy_score(y_test.numpy(), predictions.numpy())\n",
    "    print(f\"Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed56e2b-e489-4d65-8aa0-0adbc0f6ab28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
